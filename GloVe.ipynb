{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloveFile = \"glove.6B.50d.txt\"\n",
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    with open(gloveFile, encoding=\"utf8\" ) as f:\n",
    "        content = f.readlines()\n",
    "    model = {}\n",
    "    for line in content:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess(raw_text):\n",
    "\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z0-9]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n",
    "\n",
    "    return cleaned_words\n",
    "#     return words\n",
    "\n",
    "def cosine_distance_between_two_words(word1, word2):\n",
    "    import scipy\n",
    "    return (1- scipy.spatial.distance.cosine(model[word1], model[word2]))\n",
    "\n",
    "def calculate_heat_matrix_for_two_sentences(s1,s2):\n",
    "    s1 = preprocess(s1)\n",
    "    s2 = preprocess(s2)\n",
    "    result_list = [[cosine_distance_between_two_words(word1, word2) for word2 in s2] for word1 in s1]\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    result_df.columns = s2\n",
    "    result_df.index = s1\n",
    "    return result_df\n",
    "\n",
    "def cosine_distance_wordembedding_method(s1, s2):\n",
    "    import scipy\n",
    "    vector_1 = np.mean([model[word] for word in preprocess(s1)],axis=0)\n",
    "    vector_2 = np.mean([model[word] for word in preprocess(s2)],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    print('Word Embedding method with a cosine distance asses that our two sentences are similar to',round((1-cosine)*100,2),'%')\n",
    "\n",
    "def heat_map_matrix_between_two_sentences(s1,s2):\n",
    "    df = calculate_heat_matrix_for_two_sentences(s1,s2)\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(5,5)) \n",
    "    ax_blue = sns.heatmap(df, cmap=\"YlGnBu\")\n",
    "    # ax_red = sns.heatmap(df)\n",
    "    print(cosine_distance_wordembedding_method(s1, s2))\n",
    "    return ax_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadGloveModel(gloveFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss1 = \"Black Wallet  Cash 3500 Rs CNIC Drivers license Nust Student Card\"\n",
    "ss2 = \"Black Wallet  Cash 5000 Rs CNIC Drivers license Nust Student Card \"\n",
    "\n",
    "\n",
    "heat_map_matrix_between_two_sentences(ss1,ss2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
